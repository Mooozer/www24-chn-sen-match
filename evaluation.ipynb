{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d83195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "MACBERT_LOGITS_PATH = \"./macbert_large_without_EF/predictionB/logits_B_test.npy\"\n",
    "MACBERT_EF_LOGITS_PATH = \"./macbert_large_with_EF/predictionB/logits_B_test.npy\"\n",
    "\n",
    "ROBERTA_LOGITS_PATH = \"./roberta_large_without_EF/predictionB/logits_B_test.npy\"\n",
    "ROBERTA_EF_LOGITS_PATH = \"./roberta_large_with_EF/predictionB/logits_B_test.npy\"\n",
    "\n",
    "BERT_CHN_LOGITS_PATH = \"./bert_base_chinese_without_EF/predictionB/logits_B_test.npy\"\n",
    "BERT_CHN_EF_LOGITS_PATH = \"./bert_base_chinese_with_EF/predictionB/logits_B_test.npy\"\n",
    "\n",
    "BERT_MULLING_LOGITS_PATH = \"./bert_base_multilingual_without_EF/predictionB/logits_B_test.npy\"\n",
    "BERT_MULLING_EF_LOGITS_PATH = \"./bert_base_multilingual_with_EF/predictionB/logits_B_test.npy\"\n",
    "\n",
    "MACBERT_PRED_L_PATH = \"./macbert_large_without_EF/predictionB/bayes_prediction_label.npy\"\n",
    "MACBERT_EF_PRED_L_PATH = \"./macbert_large_with_EF/predictionB/bayes_prediction_label.npy\"\n",
    "\n",
    "ROBERTA_PRED_L_PATH = \"./roberta_large_without_EF/predictionB/bayes_prediction_label.npy\"\n",
    "ROBERTA_EF_PRED_L_PATH = \"./roberta_large_with_EF/predictionB/bayes_prediction_label.npy\"\n",
    "\n",
    "BERT_CHN_PRED_L_PATH = \"./bert_base_chinese_without_EF/predictionB/bayes_prediction_label.npy\"\n",
    "BERT_CHN_EF_PRED_L_PATH = \"./bert_base_chinese_with_EF/predictionB/bayes_prediction_label.npy\"\n",
    "\n",
    "BERT_MULLING_PRED_L_PATH = \"./bert_base_multilingual_without_EF/predictionB/bayes_prediction_label.npy\"\n",
    "BERT_MULLING_EF_PRED_L_PATH = \"./bert_base_multilingual_with_EF/predictionB/bayes_prediction_label.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOLD_DATA_PATH  = './GOLD_DATA_PATH/Data.txt'\n",
    "with open(GOLD_DATA_PATH,'r') as file:\n",
    "    lines = file.readlines()\n",
    "data_B = []\n",
    "for line in lines:\n",
    "    data_B.append(json.loads(line))\n",
    "data_B = pd.DataFrame(data_B)\n",
    "data_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3acfe4",
   "metadata": {},
   "source": [
    "### Evaluation of model prediction and interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564dcc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(pred_label, turb_pred_label, gold_label):\n",
    "    '''\n",
    "    pred_label: list of predicted labels\n",
    "    turb_pred_label: list of predicted labels\n",
    "    gold_label: list of predicted labels of perturbed \n",
    "    '''\n",
    "    assert len(pred_label) == len(turb_pred_label) == len(gold_label)\n",
    "    N = len(pred_label)\n",
    "    num = np.sum( (np.array(pred_label) == np.array(gold_label)) * (np.array(turb_pred_label) == np.array(gold_label)))\n",
    "    den = np.sum( (np.array(pred_label) != np.array(gold_label)) * (np.array(turb_pred_label) != np.array(gold_label)))\n",
    "    j = num/(N-den)\n",
    "    return(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(gold_label, pred_label):\n",
    "    '''\n",
    "    gold_label: int\n",
    "    pred_label: int\n",
    "    '''\n",
    "    return (gold_label == pred_label)*1.0\n",
    "\n",
    "import collections\n",
    "def rationale_macro_f1(gold_rationale, pred_rationale):\n",
    "    '''\n",
    "    gold_rationale: list of index\n",
    "    pred_rationale: list of index\n",
    "    '''\n",
    "    intersection_list = collections.Counter(gold_rationale) & collections.Counter(pred_rationale)\n",
    "    intersected_list = list(intersection_list.elements())\n",
    "    inter_len = len(intersected_list)\n",
    "    if len(pred_rationale) * inter_len == 0.0:\n",
    "        return 0.0\n",
    "    p = inter_len/(len(pred_rationale))\n",
    "    r = inter_len/(len(gold_rationale))\n",
    "    return 2 * (p*r) / (p+r)\n",
    "\n",
    "def greater(gold_rationale, pred_rationale):\n",
    "    ''' \n",
    "     A rationale is considered as a match if its Si = (intersection/union) is equal to or greater than 0.5\n",
    "    '''\n",
    "    union =  set(gold_rationale).union(pred_rationale)\n",
    "    inter =  set(gold_rationale).intersection(pred_rationale)\n",
    "    s = len(inter)/len(union)\n",
    "    return (s>0.5)*1.0\n",
    "\n",
    "def mean_avg_precision(ori_pred_rationale, turb_pred_rationale):\n",
    "    '''\n",
    "    ori_pred_rationale: list of index\n",
    "    turb_pred_rationale: list of index\n",
    "    '''\n",
    "    map = 0.0\n",
    "    if len(turb_pred_rationale) == 0:\n",
    "        return map\n",
    "    for i in range(1, len(turb_pred_rationale)+1):\n",
    "        G = 0.0\n",
    "        for j in range(i):\n",
    "            G += (turb_pred_rationale[j] in ori_pred_rationale[:i]) * 1.0\n",
    "        map += G/i\n",
    "    map /= (len(turb_pred_rationale)+1e-6)\n",
    "    return map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataframe(pred_B, data_B):\n",
    "    '''\n",
    "    pred_B: pd.DataFrame including columns {id, label, (optional) rationale_q, (optional) rationale_t}\n",
    "    data_B: pd.DataFrame including columns {sent_id, sent_label, rationale_q_idx, rationale_t_idx, rel_ids}\n",
    "    '''\n",
    "    rationale_macro_f1_list = []\n",
    "    map_list = []\n",
    "    pred_l = []\n",
    "    turb_pred_l = []\n",
    "    gold_l = []\n",
    "    greater_list = []\n",
    "    wrong_list = []    \n",
    "    \n",
    "    for i in pred_B.id:\n",
    "        gold_line = data_B[data_B['sent_id']==i]\n",
    "        gold_label = gold_line['sent_label'].item()\n",
    "\n",
    "        pred_line = pred_B[pred_B['id']==i]\n",
    "        pred_label = pred_line['label'].item()\n",
    "\n",
    "        try: \n",
    "            gold_rationale_q = gold_line['rationale_q_idx'].item()\n",
    "            gold_rationale_t = gold_line['rationale_t_idx'].item()\n",
    "            pred_rationale_q = pred_line['rationale_q'].item()\n",
    "            pred_rationale_t = pred_line['rationale_t'].item()\n",
    "            pred_rationale_q_token = [gold_line['text_q_token'].item()[k][0] for k in pred_rationale_q]\n",
    "            pred_rationale_t_token = [gold_line['text_t_token'].item()[k][0] for k in pred_rationale_t]\n",
    "            \n",
    "            rationale_macro_f1_list.append(rationale_macro_f1(gold_rationale_q, pred_rationale_q))\n",
    "            rationale_macro_f1_list.append(rationale_macro_f1(gold_rationale_t, pred_rationale_t))\n",
    "            greater_list.append(greater(gold_rationale_q, pred_rationale_q))\n",
    "            greater_list.append(greater(gold_rationale_t, pred_rationale_t))        \n",
    "       \n",
    "        except KeyError:   #no rationale reported\n",
    "            pass\n",
    "\n",
    "        except IndexError:\n",
    "            wrong_list.append(i)\n",
    "\n",
    "\n",
    "        if gold_line.sample_type.item() == 'ori': \n",
    "            rel_ids = gold_line['rel_ids'].item()\n",
    "            for rel_id in rel_ids:\n",
    "                \n",
    "                gold_line_turb = data_B[data_B['sent_id']==rel_id]\n",
    "                pred_line_trub = pred_B[pred_B['id']==rel_id]\n",
    "                \n",
    "                turb_pred_l.append(pred_line_trub['label'].item())\n",
    "                pred_l.append(pred_label)\n",
    "                gold_l.append(gold_label)\n",
    "\n",
    "                try:\n",
    "                    pred_rationale_trub_q = pred_line_trub['rationale_q'].item()\n",
    "                    pred_rationale_trub_t = pred_line_trub['rationale_t'].item()\n",
    "                    pred_rationale_trub_q_token = [gold_line_turb['text_q_token'].item()[i][0] for i in pred_rationale_trub_q]\n",
    "                    pred_rationale_trub_t_token = [gold_line_turb['text_t_token'].item()[i][0] for i in pred_rationale_trub_t]\n",
    "                    map_list.append(mean_avg_precision(pred_rationale_q_token, pred_rationale_trub_q_token))\n",
    "                    map_list.append(mean_avg_precision(pred_rationale_t_token, pred_rationale_trub_t_token))\n",
    "                    \n",
    "                except KeyError:   #no rationale reported\n",
    "                    pass\n",
    "                \n",
    "                except IndexError:\n",
    "                    wrong_list.append(rel_id)\n",
    "            \n",
    "    if not rationale_macro_f1_list: rationale_macro_f1_list = [0]\n",
    "    if not greater_list: greater_list = [0]\n",
    "    if not map_list: map_list = [0]\n",
    "\n",
    "    return { \n",
    "            'CLS_Accuracy': round(classification_report(data_B.sent_label, pred_B.label, output_dict = True)['accuracy']*100,1),\n",
    "            'CLS_Macro_f1': round(classification_report(data_B.sent_label, pred_B.label, output_dict = True)['macro avg']['f1-score']*100,1),\n",
    "            'CLS_Jaccard': round(Jaccard(pred_l,turb_pred_l, gold_l)*100,1),\n",
    "            'Recall': round(classification_report(data_B.sent_label, pred_B.label, output_dict = True)['1']['recall']*100,1),\n",
    "            'TNR': round(classification_report(data_B.sent_label, pred_B.label, output_dict = True)['0']['recall']*100,1),\n",
    "            'Rationale_Macro_f1': round(np.mean(rationale_macro_f1_list)*100,1), \n",
    "            'Rationale_IOU_f1': round(np.mean(greater_list)*100,1),\n",
    "            'Rationale_MAP': round(np.mean(map_list)*100,1),\n",
    "            # 'Rationale_Macro_f1_list': rationale_macro_f1_list,\n",
    "            # 'Rationale_IOU_f1_list': greater_list,\n",
    "            # 'Rationale_MAP_list': map_list,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe789c2",
   "metadata": {},
   "source": [
    "### Read predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred_ERNIEbase_path = \"./rationale_results/sim_rationale_erniebase.txt\"\n",
    "with open(model_pred_ERNIEbase_path, 'r') as f:  \n",
    "    model_results = f.readlines()\n",
    "pred_ERNIEbase = []\n",
    "for r in model_results:\n",
    "    line_str = r.replace('\\n','').split('\\t')\n",
    "    pred_ERNIEbase.append([int(line_str[0]), int(line_str[1]), [int(i) for i in (line_str[2].split(',') if line_str[2] else [])], [int(i) for i in (line_str[3].split(',') if line_str[3] else [])]])\n",
    "pred_ERNIEbase = pd.DataFrame(pred_ERNIEbase,columns=['id','label','rationale_q', 'rationale_t'])\n",
    "\n",
    "model_pred_shap_path = \"./rationale_results/sim_rationale_shap.txt\"\n",
    "with open(model_pred_shap_path, 'r') as f:  \n",
    "    model_results = f.readlines()\n",
    "pred_shap = []\n",
    "for r in model_results:\n",
    "    line_str = r.replace('\\n','').split('\\t')\n",
    "    pred_shap.append([int(line_str[0]), int(line_str[1]), [int(i) for i in (line_str[2].split(',') if line_str[2] else [])], [int(i) for i in (line_str[3].split(',') if line_str[3] else [])]])\n",
    "pred_shap = pd.DataFrame(pred_shap,columns=['id','label','rationale_q', 'rationale_t'])\n",
    "\n",
    "model_pred_shapprop_path = \"./rationale_results/sim_rationale_proportional_shap.txt\"\n",
    "with open(model_pred_shapprop_path, 'r') as f:  \n",
    "    model_results = f.readlines()\n",
    "pred_shap_prop = []\n",
    "for r in model_results:\n",
    "    line_str = r.replace('\\n','').split('\\t')\n",
    "    pred_shap_prop.append([int(line_str[0]), int(line_str[1]), [int(i) for i in (line_str[2].split(',') if line_str[2] else [])], [int(i) for i in (line_str[3].split(',') if line_str[3] else [])]])\n",
    "pred_shap_prop = pd.DataFrame(pred_shap_prop,columns=['id','label','rationale_q', 'rationale_t'])\n",
    "\n",
    "model_pred_ig_path = \"./rationale_results/sim_rationale_ig.txt\"\n",
    "with open(model_pred_ig_path, 'r') as f:  \n",
    "    model_results = f.readlines()\n",
    "pred_ig = []\n",
    "for r in model_results:\n",
    "    line_str = r.replace('\\n','').split('\\t')\n",
    "    pred_ig.append([int(line_str[0]), int(line_str[1]), [int(i) for i in (line_str[2].split(',') if line_str[2] else [])], [int(i) for i in (line_str[3].split(',') if line_str[3] else [])]])\n",
    "pred_ig = pd.DataFrame(pred_ig,columns=['id','label','rationale_q', 'rationale_t'])\n",
    "\n",
    "model_pred_igprop_path = \"./rationale_results/sim_rationale_proportional_ig.txt\"\n",
    "with open(model_pred_igprop_path, 'r') as f:  \n",
    "    model_results = f.readlines()\n",
    "pred_ig_prop = []\n",
    "for r in model_results:\n",
    "    line_str = r.replace('\\n','').split('\\t')\n",
    "    pred_ig_prop.append([int(line_str[0]), int(line_str[1]), [int(i) for i in (line_str[2].split(',') if line_str[2] else [])], [int(i) for i in (line_str[3].split(',') if line_str[3] else [])]])\n",
    "pred_ig_prop = pd.DataFrame(pred_ig_prop,columns=['id','label','rationale_q', 'rationale_t'])\n",
    "\n",
    "model_pred_lime_path = \"./rationale_results/sim_rationale_lime.txt\"\n",
    "with open(model_pred_lime_path, 'r') as f:  \n",
    "    model_results = f.readlines()\n",
    "pred_lime = []\n",
    "for r in model_results:\n",
    "    line_str = r.replace('\\n','').split('\\t')\n",
    "    pred_lime.append([int(line_str[0]), int(line_str[1]), [int(i) for i in (line_str[2].split(',') if line_str[2] else [])], [int(i) for i in (line_str[3].split(',') if line_str[3] else [])]])\n",
    "pred_lime = pd.DataFrame(pred_lime,columns=['id','label','rationale_q', 'rationale_t'])\n",
    "\n",
    "model_pred_limeprop_path = \"./rationale_results/sim_rationale_proportional_lime.txt\"\n",
    "with open(model_pred_limeprop_path, 'r') as f:  \n",
    "    model_results = f.readlines()\n",
    "pred_lime_prop = []\n",
    "for r in model_results:\n",
    "    line_str = r.replace('\\n','').split('\\t')\n",
    "    pred_lime_prop.append([int(line_str[0]), int(line_str[1]), [int(i) for i in (line_str[2].split(',') if line_str[2] else [])], [int(i) for i in (line_str[3].split(',') if line_str[3] else [])]])\n",
    "pred_lime_prop = pd.DataFrame(pred_lime_prop,columns=['id','label','rationale_q', 'rationale_t'])\n",
    "\n",
    "model_pred_lexicality_path = \"./rationale_results/sim_rationale_lexicality.txt\"\n",
    "with open(model_pred_lexicality_path, 'r') as f:  \n",
    "    model_results = f.readlines()\n",
    "pred_lexicality = []\n",
    "for r in model_results:\n",
    "    line_str = r.replace('\\n','').split('\\t')\n",
    "    pred_lexicality.append([int(line_str[0]), int(line_str[1]), [int(i) for i in (line_str[2].split(',') if line_str[2] else [])], [int(i) for i in (line_str[3].split(',') if line_str[3] else [])]])\n",
    "pred_lexicality = pd.DataFrame(pred_lexicality,columns=['id','label','rationale_q', 'rationale_t'])\n",
    "\n",
    "model_pred_wo_denoise_path = \"./rationale_results/sim_rationale_wo_denoising.txt\"\n",
    "with open(model_pred_wo_denoise_path, 'r') as f:  \n",
    "    model_results = f.readlines()\n",
    "wo_denoise_pred = []\n",
    "for r in model_results:\n",
    "    line_str = r.replace('\\n','').split('\\t')\n",
    "    wo_denoise_pred.append([int(line_str[0]), int(line_str[1]), [int(i) for i in (line_str[2].split(',') if line_str[2] else [])], [int(i) for i in (line_str[3].split(',') if line_str[3] else [])]])\n",
    "wo_denoise_pred = pd.DataFrame(wo_denoise_pred,columns=['id','label','rationale_q', 'rationale_t'])\n",
    "\n",
    "model_pred_path_k3 = \"./rationale_results/sim_rationale_dual_ranking.txt\"\n",
    "with open(model_pred_path_k3, 'r') as f:  \n",
    "    model_results = f.readlines()\n",
    "ours_pred_k3 = []\n",
    "for r in model_results:\n",
    "    line_str = r.replace('\\n','').split('\\t')\n",
    "    ours_pred_k3.append([int(line_str[0]), int(line_str[1]), [int(i) for i in (line_str[2].split(',') if line_str[2] else [])], [int(i) for i in (line_str[3].split(',') if line_str[3] else [])]])\n",
    "ours_pred_k3 = pd.DataFrame(ours_pred_k3,columns=['id','label','rationale_q', 'rationale_t'])\n",
    "\n",
    "gpt4_pred_path = \"./gpt/gpt4_answers/GPT4_ans.txt\"\n",
    "with open(gpt4_pred_path, 'r') as f:\n",
    "    model_results = f.readlines()\n",
    "pred_GPT4 = []\n",
    "for r in model_results:\n",
    "    r_dict = json.loads(r) \n",
    "    r_dict['rationale_q'], r_dict['rationale_t'] = r_dict['rationale'][0], r_dict['rationale'][1]\n",
    "    pred_GPT4.append(r_dict)\n",
    "pred_GPT4 = pd.DataFrame(pred_GPT4).drop(columns=['rationale'])\n",
    "\n",
    "chatgpt_pred_path = \"./gpt/chatgpt_answers/ChatGPT_ans.txt\"\n",
    "with open(chatgpt_pred_path, 'r') as f:\n",
    "    model_results = f.readlines()\n",
    "pred_chatgpt = []\n",
    "for r in model_results:\n",
    "    r_dict = json.loads(r) \n",
    "    r_dict['rationale_q'], r_dict['rationale_t'] = r_dict['rationale'][0], r_dict['rationale'][1]\n",
    "    pred_chatgpt.append(r_dict)\n",
    "pred_chatgpt = pd.DataFrame(pred_chatgpt).drop(columns=['rationale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f75a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('macbert_positive_ig    ', test_dataframe(pred_ig, data_B))\n",
    "print('macbert_prop_ig        ', test_dataframe(pred_ig_prop, data_B))\n",
    "print('pred_ChatGPT           ', test_dataframe(pred_chatgpt, data_B))\n",
    "print('pred_GPT4              ', test_dataframe(pred_GPT4, data_B))\n",
    "print('pred_ERNIEbase         ', test_dataframe(pred_ERNIEbase, data_B))\n",
    "print('macbert_positive_shap  ', test_dataframe(pred_shap, data_B))\n",
    "print('macbert_prop_shap      ', test_dataframe(pred_shap_prop, data_B))\n",
    "print('macbert_positive_lime  ', test_dataframe(pred_lime, data_B))\n",
    "print('macbert_prop_lime      ', test_dataframe(pred_lime_prop, data_B))\n",
    "print('macbert_pred_lexicality', test_dataframe(pred_lexicality, data_B))\n",
    "print('macbert_wo_denoise_pred', test_dataframe(wo_denoise_pred, data_B))\n",
    "print('macbert_dual_ranking   ', test_dataframe(ours_pred_k3, data_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MacBERT\n",
    "macbert_logits = np.load(MACBERT_LOGITS_PATH, allow_pickle=True)\n",
    "macbert_logits_pred_label =  np.argmax(macbert_logits,axis=1)\n",
    "pred_macbert = pd.DataFrame({'id':data_B['sent_id'], 'label': macbert_logits_pred_label})\n",
    "pred_macbert_bip = pd.DataFrame({'id':data_B['sent_id'], 'label': np.load(MACBERT_PRED_L_PATH, allow_pickle=True)})\n",
    "#MacBERT + EF\n",
    "macbert_EF_logits =np.load(MACBERT_EF_LOGITS_PATH, allow_pickle=True)\n",
    "macbert_EF_logits_pred_label =  np.argmax(macbert_EF_logits,axis=1)\n",
    "pred_EF_macbert = pd.DataFrame({'id':data_B['sent_id'], 'label': macbert_EF_logits_pred_label})\n",
    "pred_EF_macbert_bip = pd.DataFrame({'id':data_B['sent_id'], 'label': np.load(MACBERT_EF_PRED_L_PATH, allow_pickle=True)})\n",
    "\n",
    "#RoBERTa\n",
    "roberta_logits = np.load(ROBERTA_LOGITS_PATH, allow_pickle=True)\n",
    "roberta_logits_pred_label =  np.argmax(roberta_logits,axis=1)\n",
    "pred_roberta = pd.DataFrame({'id':data_B['sent_id'], 'label': roberta_logits_pred_label})\n",
    "pred_roberta_bip = pd.DataFrame({'id':data_B['sent_id'], 'label': np.load(ROBERTA_PRED_L_PATH, allow_pickle=True)})\n",
    "#RoBERTa + EF\n",
    "roberta_EF_logits =np.load(ROBERTA_EF_LOGITS_PATH, allow_pickle=True)\n",
    "roberta_EF_logits_pred_label =  np.argmax(roberta_EF_logits,axis=1)\n",
    "pred_EF_roberta = pd.DataFrame({'id':data_B['sent_id'], 'label': roberta_EF_logits_pred_label})\n",
    "pred_EF_roberta_bip = pd.DataFrame({'id':data_B['sent_id'], 'label': np.load(ROBERTA_EF_PRED_L_PATH, allow_pickle=True)})\n",
    "\n",
    "#BERT Chinese \n",
    "bert_chinese_logits = np.load(BERT_CHN_LOGITS_PATH, allow_pickle=True)\n",
    "bert_chinese_logits_pred_label =  np.argmax(bert_chinese_logits,axis=1)\n",
    "pred_bert_chinese = pd.DataFrame({'id':data_B['sent_id'], 'label': bert_chinese_logits_pred_label})\n",
    "pred_bert_chinese_bip = pd.DataFrame({'id':data_B['sent_id'], 'label': np.load(BERT_CHN_PRED_L_PATH, allow_pickle=True)})\n",
    "#BERT Chinese + EF\n",
    "bert_chinese_EF_logits = np.load(BERT_CHN_EF_LOGITS_PATH, allow_pickle=True)\n",
    "bert_chinese_EF_logits_pred_label =  np.argmax(bert_chinese_EF_logits,axis=1)\n",
    "pred_EF_bert_chinese = pd.DataFrame({'id':data_B['sent_id'], 'label': bert_chinese_EF_logits_pred_label})\n",
    "pred_EF_bert_chinese_bip = pd.DataFrame({'id':data_B['sent_id'], 'label': np.load(BERT_CHN_EF_PRED_L_PATH, allow_pickle=True)})\n",
    "\n",
    "#BERT multilingual \n",
    "bert_multilingual_logits = np.load(BERT_MULLING_LOGITS_PATH, allow_pickle=True)\n",
    "bert_multilingual_logits_pred_label =  np.argmax(bert_multilingual_logits,axis=1)\n",
    "pred_bert_multilingual = pd.DataFrame({'id':data_B['sent_id'], 'label': bert_multilingual_logits_pred_label})\n",
    "pred_bert_multilingual_bip = pd.DataFrame({'id':data_B['sent_id'], 'label': np.load(BERT_MULLING_PRED_L_PATH, allow_pickle=True)})\n",
    "#BERT multilingual + EF\n",
    "bert_multilingual_EF_logits = np.load(BERT_MULLING_EF_LOGITS_PATH, allow_pickle=True)\n",
    "bert_multilingual_EF_logits_pred_label =  np.argmax(bert_multilingual_EF_logits,axis=1)\n",
    "pred_EF_bert_multilingual = pd.DataFrame({'id':data_B['sent_id'], 'label': bert_multilingual_EF_logits_pred_label})\n",
    "pred_EF_bert_multilingual_bip = pd.DataFrame({'id':data_B['sent_id'], 'label': np.load(BERT_MULLING_EF_PRED_L_PATH, allow_pickle=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a14ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pred_macbert       ', test_dataframe(pred_macbert, data_B))\n",
    "print('pred_macbert+EF    ', test_dataframe(pred_EF_macbert, data_B))\n",
    "print('pred_macbert+BIP   ', test_dataframe(pred_macbert_bip, data_B))\n",
    "print('pred_macbert+EF+BIP', test_dataframe(pred_EF_macbert_bip, data_B))\n",
    "print('-------------------------------------------------')\n",
    "print('pred_roberta       ', test_dataframe(pred_roberta, data_B))\n",
    "print('pred_roberta+EF    ', test_dataframe(pred_EF_roberta, data_B))\n",
    "print('pred_roberta+BIP   ', test_dataframe(pred_roberta_bip, data_B))\n",
    "print('pred_roberta+EF+BIP', test_dataframe(pred_EF_roberta_bip, data_B))\n",
    "print('-------------------------------------------------')\n",
    "print('pred_chinese       ', test_dataframe(pred_bert_chinese, data_B))\n",
    "print('pred_chinese+EF    ', test_dataframe(pred_EF_bert_chinese, data_B))\n",
    "print('pred_chinese+BIP   ', test_dataframe(pred_bert_chinese_bip, data_B))\n",
    "print('pred_chinese+EF+BIP', test_dataframe(pred_EF_bert_chinese_bip, data_B))\n",
    "print('-------------------------------------------------')\n",
    "print('pred_multilingual       ', test_dataframe(pred_bert_multilingual, data_B))\n",
    "print('pred_multilingual+EF    ', test_dataframe(pred_EF_bert_multilingual, data_B))\n",
    "print('pred_multilingual+BIP   ', test_dataframe(pred_bert_multilingual_bip, data_B))\n",
    "print('pred_multilingual+EF+BIP', test_dataframe(pred_EF_bert_multilingual_bip, data_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6ab0b",
   "metadata": {},
   "source": [
    "## GPT4 v.s. Ours correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_ours = test_dataframe(ours_pred_k3, data_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c4d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_GPT4 = test_dataframe(pred_GPT4, data_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae6642",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ours_and_GPT4_Rationale_Macro_f1 = pd.DataFrame(\n",
    "    {\n",
    "        'ours_Rationale_Macro_f1': record_ours['Rationale_Macro_f1_list'],\n",
    "        'GPT4_Rationale_Macro_f1': record_GPT4['Rationale_Macro_f1_list']\n",
    "    }\n",
    ")\n",
    "Ours_and_GPT4_Rationale_MAP = pd.DataFrame(\n",
    "    {\n",
    "        'ours_Rationale_MAP': record_ours['Rationale_MAP_list'],\n",
    "        'GPT4_Rationale_MAP': record_GPT4['Rationale_MAP_list']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6587f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"ours_Rationale_Macro_f1\", y=\"GPT4_Rationale_Macro_f1\", \n",
    "            data=Ours_and_GPT4_Rationale_Macro_f1, \n",
    "            line_kws={\"color\": \"C3\"}, scatter_kws={'alpha':0.2})\n",
    "plt.xlabel(\"Our Rationale Macro F1\")\n",
    "plt.ylabel(\"GPT4 Rationale Macro F1\")\n",
    "plt.savefig(\"./GPT4_vs_Ours_Rationale_F1.png\", format=\"png\", dpi=700, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "sns.regplot(x=\"ours_Rationale_MAP\", y=\"GPT4_Rationale_MAP\",\n",
    "             data=Ours_and_GPT4_Rationale_MAP, \n",
    "             line_kws={\"color\": \"C3\"}, scatter_kws={'alpha':0.2})\n",
    "plt.xlabel(\"Our Rationale MAP\")\n",
    "plt.ylabel(\"GPT4 Rationale MAP\")\n",
    "plt.savefig(\"./GPT4_vs_Ours_Rationale_MAP.png\", format=\"png\", dpi=700, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
